{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import ViTConfig, ViTModel\n",
    "from transformers import ViTForImageClassification\n",
    "from transformers import ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * To load the PyTorch native [scaled_dot_product_attention](https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html), specify `attn_implementation=\"sdpa\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    attn_implementation=\"sdpa\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTModel(\n",
       "  (embeddings): ViTEmbeddings(\n",
       "    (patch_embeddings): ViTPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ViTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ViTLayer(\n",
       "        (attention): ViTSdpaAttention(\n",
       "          (attention): ViTSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (pooler): ViTPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViTModel.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embeddings.cls_token',\n",
       " 'embeddings.position_embeddings',\n",
       " 'embeddings.patch_embeddings.projection.weight',\n",
       " 'embeddings.patch_embeddings.projection.bias',\n",
       " 'encoder.layer.0.attention.attention.query.weight',\n",
       " 'encoder.layer.0.attention.attention.query.bias',\n",
       " 'encoder.layer.0.attention.attention.key.weight',\n",
       " 'encoder.layer.0.attention.attention.key.bias',\n",
       " 'encoder.layer.0.attention.attention.value.weight',\n",
       " 'encoder.layer.0.attention.attention.value.bias',\n",
       " 'encoder.layer.0.attention.output.dense.weight',\n",
       " 'encoder.layer.0.attention.output.dense.bias',\n",
       " 'encoder.layer.0.intermediate.dense.weight',\n",
       " 'encoder.layer.0.intermediate.dense.bias',\n",
       " 'encoder.layer.0.output.dense.weight',\n",
       " 'encoder.layer.0.output.dense.bias',\n",
       " 'encoder.layer.0.layernorm_before.weight',\n",
       " 'encoder.layer.0.layernorm_before.bias',\n",
       " 'encoder.layer.0.layernorm_after.weight',\n",
       " 'encoder.layer.0.layernorm_after.bias',\n",
       " 'encoder.layer.1.attention.attention.query.weight',\n",
       " 'encoder.layer.1.attention.attention.query.bias',\n",
       " 'encoder.layer.1.attention.attention.key.weight',\n",
       " 'encoder.layer.1.attention.attention.key.bias',\n",
       " 'encoder.layer.1.attention.attention.value.weight',\n",
       " 'encoder.layer.1.attention.attention.value.bias',\n",
       " 'encoder.layer.1.attention.output.dense.weight',\n",
       " 'encoder.layer.1.attention.output.dense.bias',\n",
       " 'encoder.layer.1.intermediate.dense.weight',\n",
       " 'encoder.layer.1.intermediate.dense.bias',\n",
       " 'encoder.layer.1.output.dense.weight',\n",
       " 'encoder.layer.1.output.dense.bias',\n",
       " 'encoder.layer.1.layernorm_before.weight',\n",
       " 'encoder.layer.1.layernorm_before.bias',\n",
       " 'encoder.layer.1.layernorm_after.weight',\n",
       " 'encoder.layer.1.layernorm_after.bias',\n",
       " 'encoder.layer.2.attention.attention.query.weight',\n",
       " 'encoder.layer.2.attention.attention.query.bias',\n",
       " 'encoder.layer.2.attention.attention.key.weight',\n",
       " 'encoder.layer.2.attention.attention.key.bias',\n",
       " 'encoder.layer.2.attention.attention.value.weight',\n",
       " 'encoder.layer.2.attention.attention.value.bias',\n",
       " 'encoder.layer.2.attention.output.dense.weight',\n",
       " 'encoder.layer.2.attention.output.dense.bias',\n",
       " 'encoder.layer.2.intermediate.dense.weight',\n",
       " 'encoder.layer.2.intermediate.dense.bias',\n",
       " 'encoder.layer.2.output.dense.weight',\n",
       " 'encoder.layer.2.output.dense.bias',\n",
       " 'encoder.layer.2.layernorm_before.weight',\n",
       " 'encoder.layer.2.layernorm_before.bias',\n",
       " 'encoder.layer.2.layernorm_after.weight',\n",
       " 'encoder.layer.2.layernorm_after.bias',\n",
       " 'encoder.layer.3.attention.attention.query.weight',\n",
       " 'encoder.layer.3.attention.attention.query.bias',\n",
       " 'encoder.layer.3.attention.attention.key.weight',\n",
       " 'encoder.layer.3.attention.attention.key.bias',\n",
       " 'encoder.layer.3.attention.attention.value.weight',\n",
       " 'encoder.layer.3.attention.attention.value.bias',\n",
       " 'encoder.layer.3.attention.output.dense.weight',\n",
       " 'encoder.layer.3.attention.output.dense.bias',\n",
       " 'encoder.layer.3.intermediate.dense.weight',\n",
       " 'encoder.layer.3.intermediate.dense.bias',\n",
       " 'encoder.layer.3.output.dense.weight',\n",
       " 'encoder.layer.3.output.dense.bias',\n",
       " 'encoder.layer.3.layernorm_before.weight',\n",
       " 'encoder.layer.3.layernorm_before.bias',\n",
       " 'encoder.layer.3.layernorm_after.weight',\n",
       " 'encoder.layer.3.layernorm_after.bias',\n",
       " 'encoder.layer.4.attention.attention.query.weight',\n",
       " 'encoder.layer.4.attention.attention.query.bias',\n",
       " 'encoder.layer.4.attention.attention.key.weight',\n",
       " 'encoder.layer.4.attention.attention.key.bias',\n",
       " 'encoder.layer.4.attention.attention.value.weight',\n",
       " 'encoder.layer.4.attention.attention.value.bias',\n",
       " 'encoder.layer.4.attention.output.dense.weight',\n",
       " 'encoder.layer.4.attention.output.dense.bias',\n",
       " 'encoder.layer.4.intermediate.dense.weight',\n",
       " 'encoder.layer.4.intermediate.dense.bias',\n",
       " 'encoder.layer.4.output.dense.weight',\n",
       " 'encoder.layer.4.output.dense.bias',\n",
       " 'encoder.layer.4.layernorm_before.weight',\n",
       " 'encoder.layer.4.layernorm_before.bias',\n",
       " 'encoder.layer.4.layernorm_after.weight',\n",
       " 'encoder.layer.4.layernorm_after.bias',\n",
       " 'encoder.layer.5.attention.attention.query.weight',\n",
       " 'encoder.layer.5.attention.attention.query.bias',\n",
       " 'encoder.layer.5.attention.attention.key.weight',\n",
       " 'encoder.layer.5.attention.attention.key.bias',\n",
       " 'encoder.layer.5.attention.attention.value.weight',\n",
       " 'encoder.layer.5.attention.attention.value.bias',\n",
       " 'encoder.layer.5.attention.output.dense.weight',\n",
       " 'encoder.layer.5.attention.output.dense.bias',\n",
       " 'encoder.layer.5.intermediate.dense.weight',\n",
       " 'encoder.layer.5.intermediate.dense.bias',\n",
       " 'encoder.layer.5.output.dense.weight',\n",
       " 'encoder.layer.5.output.dense.bias',\n",
       " 'encoder.layer.5.layernorm_before.weight',\n",
       " 'encoder.layer.5.layernorm_before.bias',\n",
       " 'encoder.layer.5.layernorm_after.weight',\n",
       " 'encoder.layer.5.layernorm_after.bias',\n",
       " 'encoder.layer.6.attention.attention.query.weight',\n",
       " 'encoder.layer.6.attention.attention.query.bias',\n",
       " 'encoder.layer.6.attention.attention.key.weight',\n",
       " 'encoder.layer.6.attention.attention.key.bias',\n",
       " 'encoder.layer.6.attention.attention.value.weight',\n",
       " 'encoder.layer.6.attention.attention.value.bias',\n",
       " 'encoder.layer.6.attention.output.dense.weight',\n",
       " 'encoder.layer.6.attention.output.dense.bias',\n",
       " 'encoder.layer.6.intermediate.dense.weight',\n",
       " 'encoder.layer.6.intermediate.dense.bias',\n",
       " 'encoder.layer.6.output.dense.weight',\n",
       " 'encoder.layer.6.output.dense.bias',\n",
       " 'encoder.layer.6.layernorm_before.weight',\n",
       " 'encoder.layer.6.layernorm_before.bias',\n",
       " 'encoder.layer.6.layernorm_after.weight',\n",
       " 'encoder.layer.6.layernorm_after.bias',\n",
       " 'encoder.layer.7.attention.attention.query.weight',\n",
       " 'encoder.layer.7.attention.attention.query.bias',\n",
       " 'encoder.layer.7.attention.attention.key.weight',\n",
       " 'encoder.layer.7.attention.attention.key.bias',\n",
       " 'encoder.layer.7.attention.attention.value.weight',\n",
       " 'encoder.layer.7.attention.attention.value.bias',\n",
       " 'encoder.layer.7.attention.output.dense.weight',\n",
       " 'encoder.layer.7.attention.output.dense.bias',\n",
       " 'encoder.layer.7.intermediate.dense.weight',\n",
       " 'encoder.layer.7.intermediate.dense.bias',\n",
       " 'encoder.layer.7.output.dense.weight',\n",
       " 'encoder.layer.7.output.dense.bias',\n",
       " 'encoder.layer.7.layernorm_before.weight',\n",
       " 'encoder.layer.7.layernorm_before.bias',\n",
       " 'encoder.layer.7.layernorm_after.weight',\n",
       " 'encoder.layer.7.layernorm_after.bias',\n",
       " 'encoder.layer.8.attention.attention.query.weight',\n",
       " 'encoder.layer.8.attention.attention.query.bias',\n",
       " 'encoder.layer.8.attention.attention.key.weight',\n",
       " 'encoder.layer.8.attention.attention.key.bias',\n",
       " 'encoder.layer.8.attention.attention.value.weight',\n",
       " 'encoder.layer.8.attention.attention.value.bias',\n",
       " 'encoder.layer.8.attention.output.dense.weight',\n",
       " 'encoder.layer.8.attention.output.dense.bias',\n",
       " 'encoder.layer.8.intermediate.dense.weight',\n",
       " 'encoder.layer.8.intermediate.dense.bias',\n",
       " 'encoder.layer.8.output.dense.weight',\n",
       " 'encoder.layer.8.output.dense.bias',\n",
       " 'encoder.layer.8.layernorm_before.weight',\n",
       " 'encoder.layer.8.layernorm_before.bias',\n",
       " 'encoder.layer.8.layernorm_after.weight',\n",
       " 'encoder.layer.8.layernorm_after.bias',\n",
       " 'encoder.layer.9.attention.attention.query.weight',\n",
       " 'encoder.layer.9.attention.attention.query.bias',\n",
       " 'encoder.layer.9.attention.attention.key.weight',\n",
       " 'encoder.layer.9.attention.attention.key.bias',\n",
       " 'encoder.layer.9.attention.attention.value.weight',\n",
       " 'encoder.layer.9.attention.attention.value.bias',\n",
       " 'encoder.layer.9.attention.output.dense.weight',\n",
       " 'encoder.layer.9.attention.output.dense.bias',\n",
       " 'encoder.layer.9.intermediate.dense.weight',\n",
       " 'encoder.layer.9.intermediate.dense.bias',\n",
       " 'encoder.layer.9.output.dense.weight',\n",
       " 'encoder.layer.9.output.dense.bias',\n",
       " 'encoder.layer.9.layernorm_before.weight',\n",
       " 'encoder.layer.9.layernorm_before.bias',\n",
       " 'encoder.layer.9.layernorm_after.weight',\n",
       " 'encoder.layer.9.layernorm_after.bias',\n",
       " 'encoder.layer.10.attention.attention.query.weight',\n",
       " 'encoder.layer.10.attention.attention.query.bias',\n",
       " 'encoder.layer.10.attention.attention.key.weight',\n",
       " 'encoder.layer.10.attention.attention.key.bias',\n",
       " 'encoder.layer.10.attention.attention.value.weight',\n",
       " 'encoder.layer.10.attention.attention.value.bias',\n",
       " 'encoder.layer.10.attention.output.dense.weight',\n",
       " 'encoder.layer.10.attention.output.dense.bias',\n",
       " 'encoder.layer.10.intermediate.dense.weight',\n",
       " 'encoder.layer.10.intermediate.dense.bias',\n",
       " 'encoder.layer.10.output.dense.weight',\n",
       " 'encoder.layer.10.output.dense.bias',\n",
       " 'encoder.layer.10.layernorm_before.weight',\n",
       " 'encoder.layer.10.layernorm_before.bias',\n",
       " 'encoder.layer.10.layernorm_after.weight',\n",
       " 'encoder.layer.10.layernorm_after.bias',\n",
       " 'encoder.layer.11.attention.attention.query.weight',\n",
       " 'encoder.layer.11.attention.attention.query.bias',\n",
       " 'encoder.layer.11.attention.attention.key.weight',\n",
       " 'encoder.layer.11.attention.attention.key.bias',\n",
       " 'encoder.layer.11.attention.attention.value.weight',\n",
       " 'encoder.layer.11.attention.attention.value.bias',\n",
       " 'encoder.layer.11.attention.output.dense.weight',\n",
       " 'encoder.layer.11.attention.output.dense.bias',\n",
       " 'encoder.layer.11.intermediate.dense.weight',\n",
       " 'encoder.layer.11.intermediate.dense.bias',\n",
       " 'encoder.layer.11.output.dense.weight',\n",
       " 'encoder.layer.11.output.dense.bias',\n",
       " 'encoder.layer.11.layernorm_before.weight',\n",
       " 'encoder.layer.11.layernorm_before.bias',\n",
       " 'encoder.layer.11.layernorm_after.weight',\n",
       " 'encoder.layer.11.layernorm_after.bias',\n",
       " 'layernorm.weight',\n",
       " 'layernorm.bias',\n",
       " 'pooler.dense.weight',\n",
       " 'pooler.dense.bias']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0182,  0.2526, -0.1410,  ...,  0.0096,  0.2832, -0.0863],\n",
       "        [ 0.1067,  0.3417,  0.0522,  ...,  0.2693, -0.0120, -0.0830],\n",
       "        [ 0.0321, -0.1272, -0.1964,  ...,  0.0236,  0.0351, -0.1173],\n",
       "        ...,\n",
       "        [ 0.0295,  0.0133,  0.1008,  ...,  0.0110, -0.0184, -0.1565],\n",
       "        [ 0.0468,  0.0314, -0.0288,  ..., -0.0640,  0.0282, -0.2290],\n",
       "        [ 0.0561,  0.1137, -0.0054,  ..., -0.0041,  0.0535,  0.0439]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layer[0].attention.attention.query.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-2.0960e-01, -4.7015e-02, -4.5674e-01, -4.2780e-02, -4.1338e-01,\n",
       "        -4.6941e-01, -4.6764e-01,  4.9690e-01, -4.6630e-01,  3.0337e-01,\n",
       "        -3.1801e-01, -4.9101e-02, -1.3426e-01, -3.3898e-01,  1.3503e-02,\n",
       "         2.1375e-01, -4.8420e-02,  4.7879e-01,  3.1575e-01, -4.9546e-01,\n",
       "         5.1784e-02,  7.6204e-02,  4.1113e-01, -8.2276e-02, -1.3096e-01,\n",
       "        -4.8452e-01, -4.3603e-01, -1.0970e-01,  2.7601e-01, -2.7287e-02,\n",
       "         3.6353e-01,  2.1364e-01,  4.9591e-01, -1.0548e-01, -1.8365e-01,\n",
       "         6.5965e-03,  5.3930e-02, -9.0674e-02, -1.5761e-01,  2.4053e-01,\n",
       "         4.3008e-01,  1.0813e-01,  3.5249e-01,  4.7268e-01,  2.0266e-01,\n",
       "         4.1082e-01,  7.8327e-02,  1.0505e-01,  1.0408e-01, -4.1858e-01,\n",
       "        -1.4877e-01, -4.9772e-01, -3.5321e-02, -7.3208e-02,  3.9252e-02,\n",
       "         4.9966e-01, -9.2619e-02, -4.3568e-01,  1.4587e-01, -4.1887e-01,\n",
       "         4.5389e-01, -1.1517e-01,  1.8625e-01,  6.2355e-04, -9.4567e-02,\n",
       "         1.7681e-01, -3.4719e-02,  3.3379e-01,  4.4441e-02,  1.7967e-01,\n",
       "         4.0479e-02,  1.0965e-01,  5.6725e-02, -1.0630e-01, -4.3573e-01,\n",
       "        -4.7017e-02,  4.4099e-01, -4.0428e-01, -3.1461e-03,  3.5320e-01,\n",
       "         4.3133e-01, -2.7397e-03, -3.8802e-01,  3.1860e-02, -1.9806e-01,\n",
       "         3.3659e-01, -4.4166e-01, -1.7007e-01, -3.7843e-01,  1.2248e-01,\n",
       "         1.0132e-01, -1.7316e-02, -3.9583e-01,  1.2524e-02, -1.5196e-01,\n",
       "        -4.0259e-01, -7.1787e-02, -3.0770e-01, -3.7350e-01,  1.5815e-02,\n",
       "        -4.5541e-01,  1.0774e-01, -4.6406e-01, -4.6901e-01,  7.1047e-03,\n",
       "         4.5546e-01,  3.3239e-02,  2.5443e-02, -6.5972e-02,  4.4431e-01,\n",
       "         1.5156e-01,  1.9547e-01, -7.2845e-04, -3.4856e-01, -1.3481e-01,\n",
       "         1.3214e-01,  1.4358e-01,  4.7804e-01, -9.3498e-02, -1.8598e-01,\n",
       "        -2.4955e-01,  2.4776e-01,  1.9153e-02, -2.9548e-01,  7.1115e-03,\n",
       "         5.5778e-02, -1.0053e-01, -4.2995e-01,  6.8355e-03, -4.1123e-01,\n",
       "         1.3135e-01, -4.7764e-01, -4.3605e-01, -4.7076e-01, -1.6898e-01,\n",
       "         2.7877e-01,  3.9764e-01, -8.4566e-02,  4.5196e-01, -1.4463e-01,\n",
       "         4.6893e-02,  4.7464e-01, -3.1058e-01, -1.1477e-01, -4.3365e-01,\n",
       "         1.7706e-01,  3.7523e-01, -2.4256e-01, -2.3298e-01,  3.7104e-01,\n",
       "         3.2095e-01,  2.3440e-02, -2.8396e-02, -2.3363e-01, -9.5535e-02,\n",
       "         4.7126e-02, -4.7176e-01, -3.9921e-01, -9.5175e-02, -2.1244e-01,\n",
       "        -1.0859e-02,  5.2327e-02,  3.4069e-01,  7.5841e-02,  3.0205e-01,\n",
       "        -1.6890e-01, -1.6330e-01,  1.4586e-02,  1.5048e-02,  3.7102e-01,\n",
       "        -9.1766e-02, -2.7184e-01,  5.0156e-03, -2.9297e-02, -2.8130e-01,\n",
       "         3.1067e-02, -1.0678e-01,  4.5441e-01,  1.2619e-01,  7.1946e-02,\n",
       "        -4.9634e-01, -8.4225e-02, -5.6713e-03,  1.8703e-02,  1.0473e-01,\n",
       "        -3.6857e-01, -4.6351e-02, -1.3618e-01, -3.6125e-01, -3.9651e-01,\n",
       "        -7.1025e-02,  2.5168e-01, -1.5405e-02,  2.3199e-02,  6.9987e-02,\n",
       "        -1.1698e-01, -2.3267e-02,  1.0317e-01,  9.2356e-02, -2.5266e-02,\n",
       "        -1.1060e-02, -2.8498e-01, -2.5961e-01,  3.9531e-02, -3.2526e-01,\n",
       "         2.6187e-01,  1.0253e-01, -1.2408e-02,  3.4348e-02, -4.4946e-02,\n",
       "        -4.4437e-01, -7.8310e-03,  4.3577e-02,  1.3723e-01, -4.0708e-01,\n",
       "        -3.0615e-02, -4.2265e-01, -2.1755e-02, -1.5881e-02,  2.0680e-03,\n",
       "        -3.7132e-03, -6.9084e-02,  5.4914e-03, -1.4779e-02,  4.4966e-02,\n",
       "        -4.5554e-01, -1.1092e-01,  7.3777e-03, -3.7897e-01, -3.7719e-03,\n",
       "        -2.1091e-01,  6.7261e-03,  2.1247e-02, -2.6651e-02, -4.8056e-01,\n",
       "        -2.5115e-01, -5.1333e-04,  3.0874e-02,  8.4111e-03,  2.9686e-02,\n",
       "         2.5947e-02, -2.3568e-02, -1.8124e-01, -4.7080e-02, -6.0161e-02,\n",
       "        -3.5230e-02, -8.1425e-03, -1.1570e-01,  4.9032e-01, -1.8440e-01,\n",
       "         7.7974e-03, -9.2593e-02,  3.7603e-01, -3.6379e-01, -8.1440e-03,\n",
       "         5.3112e-01,  4.6360e-01, -1.3050e-01, -7.8449e-02, -2.1318e-01,\n",
       "        -8.3622e-02,  5.1777e-02, -1.5129e-01, -7.2033e-03, -8.8888e-02,\n",
       "         2.5137e-02,  1.0128e-01, -5.4716e-02,  1.5405e-01,  2.3842e-01,\n",
       "         7.8778e-02,  1.7883e-02, -1.4194e-02,  5.1621e-01, -5.2237e-02,\n",
       "        -2.7090e-01, -2.5236e-01, -3.3939e-02,  1.9350e-01, -1.0642e-01,\n",
       "         1.0075e-01,  6.9137e-02,  3.7789e-01, -1.7626e-01, -2.8390e-01,\n",
       "        -3.0921e-01, -1.3243e-01,  1.1806e-01, -4.4689e-02,  4.9979e-02,\n",
       "        -1.7282e-01,  1.0485e-02,  1.0598e-02,  4.3588e-02, -6.4807e-02,\n",
       "         5.6370e-01, -1.3673e-01,  1.0373e-01, -9.8474e-02, -9.0431e-02,\n",
       "         2.7263e-01, -1.4677e-01,  2.6403e-01,  1.0999e-01, -1.3462e-01,\n",
       "        -7.7628e-02,  7.1235e-02, -3.5408e-01, -2.3471e-03,  1.0175e-01,\n",
       "         1.6857e-02,  4.5248e-02, -1.3378e-02, -1.5287e-01,  1.0025e-01,\n",
       "         2.5631e-01,  1.5961e-01, -9.4517e-02,  2.2688e-01,  5.6958e-02,\n",
       "         1.0038e-02,  5.3744e-02, -9.3497e-02,  3.6963e-01, -6.2300e-02,\n",
       "        -1.8268e-02, -5.0053e-01, -3.4445e-01,  3.8236e-02,  4.0264e-01,\n",
       "        -5.0158e-01, -3.9866e-03, -5.3283e-02, -1.3746e-02,  1.4156e-01,\n",
       "         4.8535e-01,  4.4595e-02, -6.3959e-02, -1.0454e-02,  3.1764e-02,\n",
       "        -5.0101e-01, -8.7513e-02,  4.4116e-01,  6.5660e-02, -1.5720e-02,\n",
       "        -3.8018e-01,  3.6202e-02, -3.8516e-01,  4.3142e-01,  5.0319e-02,\n",
       "        -4.6190e-04,  4.0988e-01, -6.6868e-02,  1.2121e-01, -4.4853e-02,\n",
       "         6.7139e-02, -2.4365e-02, -2.7552e-03, -1.9897e-03,  2.7701e-02,\n",
       "         7.4587e-02, -4.4843e-01,  4.8384e-02, -5.1204e-01, -3.4097e-01,\n",
       "        -1.4712e-01, -3.3985e-01, -2.6959e-02,  7.3948e-02, -4.6051e-01,\n",
       "        -3.2860e-01,  1.0366e-01,  4.9081e-01, -4.4288e-01,  4.9677e-04,\n",
       "         4.5056e-01,  2.7696e-01, -4.1073e-02, -8.6623e-02, -4.9788e-01,\n",
       "         3.9727e-01,  1.9388e-01,  5.0615e-01, -4.8989e-01,  2.3201e-01,\n",
       "        -6.9806e-02,  2.1389e-01,  4.0306e-01, -2.2137e-03, -1.6804e-01,\n",
       "        -1.7176e-01, -4.3556e-01,  2.5683e-02, -3.5101e-01, -1.4889e-01,\n",
       "        -1.1659e-01,  1.8450e-01, -5.6579e-04,  3.2718e-02,  4.3422e-01,\n",
       "         1.3533e-01, -4.1648e-01, -4.6056e-01, -7.5241e-03, -6.0198e-02,\n",
       "         4.0712e-01, -1.2436e-01, -1.3199e-02, -2.4496e-01, -3.0506e-02,\n",
       "        -9.1491e-02,  4.2495e-01,  4.2384e-01,  7.5247e-02,  7.2476e-02,\n",
       "        -3.9327e-02, -2.2983e-01,  4.4473e-01, -1.4041e-01, -4.8803e-01,\n",
       "         3.9713e-01,  4.5398e-01, -2.5199e-03,  5.3517e-02, -4.2913e-01,\n",
       "         4.8577e-01,  4.8340e-01,  1.8995e-02,  4.7893e-01, -6.3348e-02,\n",
       "        -7.6425e-02, -2.9636e-02, -8.3642e-03,  4.6913e-01,  1.2877e-01,\n",
       "         2.4041e-02, -2.9658e-01,  1.3727e-01,  2.5391e-01,  3.5252e-02,\n",
       "        -2.1703e-02,  9.4678e-02,  2.0450e-01, -5.9014e-02,  2.0677e-01,\n",
       "        -1.6614e-01,  4.7047e-01,  9.2516e-02, -5.7936e-02, -3.6234e-01,\n",
       "        -1.3972e-01,  3.3013e-01, -1.4976e-01, -2.2141e-02,  3.8199e-02,\n",
       "         4.3616e-02, -1.1127e-01,  2.0017e-01, -4.1640e-02,  3.2858e-01,\n",
       "         5.3564e-02, -6.6879e-02,  3.0623e-02,  2.2014e-01, -8.1748e-03,\n",
       "         4.1431e-01, -5.0454e-02,  2.7981e-02,  1.5931e-02, -3.3684e-01,\n",
       "         5.5780e-03, -2.7131e-02,  3.1871e-01,  1.1546e-01,  5.7298e-02,\n",
       "         2.5359e-02, -1.1918e-01, -2.6494e-02,  6.9906e-02,  3.3052e-01,\n",
       "        -5.1418e-03, -1.4060e-02, -1.1271e-02, -5.3664e-03,  7.4853e-03,\n",
       "         3.8536e-02,  4.7643e-02,  1.0101e-01, -1.0793e-01, -5.1024e-02,\n",
       "         5.0710e-04,  2.8287e-02, -6.4778e-03, -1.0053e-01,  1.2277e-01,\n",
       "        -1.5552e-01,  2.3449e-01, -1.7413e-01,  3.0677e-01,  2.6094e-01,\n",
       "         4.1787e-02,  5.3346e-02,  2.9042e-01,  2.6485e-01,  5.5769e-03,\n",
       "         3.4745e-01,  3.0222e-01, -3.8915e-03,  3.5640e-02, -4.9191e-02,\n",
       "         2.6914e-02,  6.4332e-03,  2.4423e-01, -7.3301e-02, -8.3187e-02,\n",
       "         6.0955e-02,  3.0658e-01,  2.3131e-01,  1.7079e-01, -5.0204e-01,\n",
       "        -1.5445e-01,  2.0005e-01, -4.2444e-01, -3.4237e-02,  2.2651e-01,\n",
       "         4.9694e-01, -4.1339e-01,  1.7887e-01,  2.9463e-02,  1.6830e-01,\n",
       "         1.1598e-01, -7.4738e-02, -2.8392e-01,  1.7751e-01,  1.0026e-01,\n",
       "        -8.5017e-02, -2.4266e-01, -1.3277e-01,  8.7605e-02, -4.5016e-01,\n",
       "         9.9279e-02, -4.7408e-01,  2.9274e-02,  1.1334e-01,  1.5106e-01,\n",
       "         2.9306e-01,  2.8216e-01,  4.2453e-01,  1.2525e-01,  3.9381e-01,\n",
       "        -4.4101e-01, -6.1623e-02, -1.6986e-02, -2.1355e-02, -9.5958e-02,\n",
       "         8.5340e-02, -3.4175e-01,  4.5588e-01,  4.6293e-01,  2.0159e-01,\n",
       "         1.7727e-01,  4.0841e-01,  5.0515e-01,  4.4462e-01, -1.0706e-01,\n",
       "         9.9727e-02,  1.8139e-02, -2.5658e-01, -4.7856e-01, -9.3554e-02,\n",
       "         3.4102e-02,  4.9522e-01,  4.7852e-02, -2.6566e-02, -5.7127e-02,\n",
       "        -4.3856e-01,  4.5867e-01, -9.1068e-02, -2.1748e-02, -2.9764e-01,\n",
       "         1.2738e-01, -1.4150e-01,  1.2265e-01, -3.1042e-02, -7.4289e-02,\n",
       "         4.2321e-02, -1.1209e-01,  1.5503e-01,  5.5819e-02, -2.6793e-01,\n",
       "        -3.9150e-01,  1.0326e-01,  1.6038e-01, -1.5572e-01, -8.6330e-02,\n",
       "         1.2260e-01, -3.3362e-01, -8.3667e-02,  1.0102e-01, -5.6402e-02,\n",
       "        -1.6629e-01, -1.6650e-01, -1.2402e-01,  1.0858e-02, -1.6251e-01,\n",
       "         1.0152e-01, -2.5091e-02,  1.6047e-02,  5.8489e-02, -5.3942e-02,\n",
       "        -1.3806e-03,  1.3406e-01,  2.0347e-02, -4.8014e-02,  1.5720e-01,\n",
       "         5.3784e-02,  3.8744e-02,  1.1910e-01, -2.6459e-01, -2.7521e-02,\n",
       "         1.6444e-01, -8.4670e-02,  1.1834e-01,  4.0536e-01,  1.4276e-01,\n",
       "        -9.5410e-02, -2.5623e-01, -9.9907e-02, -1.1612e-01,  1.4770e-01,\n",
       "        -8.8635e-02,  8.7864e-02, -7.8736e-03,  5.0077e-02,  1.5300e-01,\n",
       "        -3.3125e-03, -6.8154e-02,  7.3371e-02, -4.8883e-01,  1.7162e-01,\n",
       "        -5.8945e-02, -4.3209e-02,  1.0812e-03,  2.5975e-01, -1.4708e-02,\n",
       "        -2.8957e-01, -1.0803e-02, -3.0896e-01, -2.0796e-01,  4.7461e-02,\n",
       "        -1.4202e-02,  3.9055e-02, -2.0691e-02, -3.1489e-03, -7.4140e-02,\n",
       "         3.0183e-01,  4.1834e-02,  2.7250e-02, -4.4392e-02, -3.8117e-02,\n",
       "        -2.8167e-02, -1.3250e-02,  2.8666e-02,  3.9288e-02, -1.3280e-02,\n",
       "         4.4926e-02, -3.4481e-02, -2.1593e-02,  3.6468e-01,  4.4582e-02,\n",
       "         2.1504e-02,  3.8777e-01, -1.0755e-02, -3.5716e-01,  1.9708e-03,\n",
       "         7.0273e-03,  6.4154e-02,  1.9733e-01, -4.7940e-02,  1.6380e-02,\n",
       "        -3.6140e-03, -3.7433e-02,  1.1768e-02,  3.8884e-01,  1.3715e-01,\n",
       "        -3.9892e-01, -9.3758e-02, -7.4950e-02, -3.4421e-01, -6.8943e-03,\n",
       "         3.0374e-02, -7.6646e-03,  3.0181e-02, -4.0230e-01,  2.1600e-02,\n",
       "         2.0538e-01, -4.2313e-01,  3.2228e-01, -3.4741e-01, -2.5637e-03,\n",
       "         2.7328e-01,  3.4672e-01, -3.2667e-01, -1.9166e-02,  1.1014e-01,\n",
       "        -5.4581e-01, -2.1814e-01, -8.5706e-03, -2.0904e-03, -1.5027e-03,\n",
       "         7.0081e-02, -6.8485e-02, -3.3149e-01, -3.3024e-01, -2.7927e-01,\n",
       "         3.9205e-01,  1.0009e-01, -5.8932e-01,  1.3827e-01, -5.1080e-02,\n",
       "         1.2625e-01, -1.3062e-01,  1.2909e-01,  1.8636e-02,  4.5681e-01,\n",
       "         5.3489e-01,  2.5361e-01,  1.8062e-01, -4.4522e-01, -2.0719e-01,\n",
       "         3.5147e-02, -1.8576e-01,  1.8603e-01,  1.2050e-01, -2.5236e-01,\n",
       "        -5.7633e-01,  5.5471e-02,  2.5866e-02,  6.0196e-01,  9.1275e-02,\n",
       "        -4.3244e-01, -1.0262e-01,  6.5685e-01,  7.1310e-02, -9.3626e-02,\n",
       "        -2.0906e-02,  6.8231e-02,  1.7450e-01, -6.8634e-02, -1.6580e-01,\n",
       "        -5.0753e-02,  4.4193e-01, -5.1645e-01, -1.0161e-02,  7.0536e-03,\n",
       "         6.4911e-01,  6.8044e-01, -4.8203e-01, -3.0298e-02,  4.0683e-01,\n",
       "        -6.2334e-03,  3.7606e-01, -1.2342e-01, -1.2665e-01, -6.2898e-01,\n",
       "        -1.2356e-01, -2.5816e-01,  1.0956e-01], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layer[0].attention.attention.query.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
